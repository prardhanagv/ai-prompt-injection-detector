# ğŸ¤– AI Prompt Injection Detector

A lightweight Python tool that detects potentially malicious **prompt injections** in AI input text.  
It checks if the userâ€™s prompt tries to bypass restrictions or reveal confidential information.  
If found, it flags the prompt as **â€œSuspiciousâ€** or **â€œSafeâ€**.

---

## âœ¨ Features
- Detects risky and manipulative prompt patterns.
- Helps safeguard AI systems from jailbreak or override attempts.
- Simple and easy-to-customize code.

---

## ğŸ› ï¸ Installation

```bash
pip install nltk

---
ğŸš€ How It Works

The tool uses regex to scan for phrases that might indicate prompt injection.

If such patterns are found, it flags the input as suspicious.

Otherwise, it marks it safe.

ğŸ“š Future Improvements

Integrate with OpenAI API for real-time scanning.

Add a larger dataset of known risky patterns.

Support for multilingual prompt analysis.

ğŸ§  Author

Created with â¤ï¸ by Prardhana


ğŸªª License

This project is licensed under the MIT License.

